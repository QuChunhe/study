
# Real Analysis


Borel Subsets in X are measurable

B = Borel sets = sigma algebra generated by all  open  subsets

a = sigma algebra induced by  outer measure

B belongs  to a

metric outer measure => Borel  subset  of R^n are Lebesgue measurable


<<实变函数理论和方法>>


# Statistics

[Type I and type II errors](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors)

* A type I error (or error of the first kind) is the incorrect rejection of a true null hypothesis. Usually a type I error leads one to conclude that a supposed effect or relationship exists when in fact it doesn't. Examples of type I errors include a test that shows a patient to have a disease when in fact the patient does not have the disease, a fire alarm going on indicating a fire when in fact there is no fire, or an experiment indicating that a medical treatment should cure a disease when in fact it does not.
* A type II error (or error of the second kind) is the failure to reject a false null hypothesis. Examples of type II errors would be a blood test failing to detect the disease it was designed to detect, in a patient who really has the disease; a fire breaking out and the fire alarm does not ring; or a clinical trial of a medical treatment failing to show that the treatment works when really it does.


[What Educated Citizens Should Know About Statistics and Probability](https://www.ics.uci.edu/~jutts/AmerStat2003.pdf)


1. When it can be concluded that a relationship is one of cause and effect, and when it cannot, including the difference between randomized experiments and observational studies.
2. The difference between statistical signicance and practical importance, especially when using large sample sizes
3. The difference between finding "no effect" or "no difference" and finding no statistically significant effect or difference, expecially when using small sample size.
4. Common sources of bias in surveys and experiments, such as poor wording of questions, volunteer response, and socially desirable answers.
5. The idea that coincidences and seemingly very improbable events are not uncommon because there are so many possibilities.
6. "Confusion of the inverse" in which a conditional probability in one direction is confused with the conditional probability in the other direction.
7. Understading that variability is natural, and that "normal" is not the same as "average".




<<统计学方法与数据分析引论>>(《An Introduction to Statistical Methods and Data Analysis》)
  
  总体：所有测量值的集合   
  样本：从总体中挑选出来的测量值集合 
  
  
  clinical trial（临床实验）
  
  
  统计学的目标在于基于从感兴趣的总体抽得的样本的测量信息，对该总体作出推断。
  
  数据收集方案的设计，数据的概括和统计分析，解释研究结果
  
  That is, statistics is the science of Learning from Data.
  
  Learning from Data: (1) defining the problem, (2) collecting the data, (3) summarizing
the data, and (4) analyzing the data, interpreting the analyses, and communicating
the results.


someone has defined the problem to be examined (Step 1), developed a plan for collecting
data to address the problem (Step 2), and summarized the data and prepared the
data for analysis (Step 3). Then following the analysis of the data, the results of the
analysis must be interpreted and communicated either verbally or in written form
to the intended audience (Step 4).

A population is the set of all measurements of interest to the sample collector.

A sample is any subset of measurements selected from the population.


The patterns and trends discovered in the analysis of the data are defined
as data mining models.



# Bayesian Statistics

Bradley P. Carlin and Thomas A. Louis,  Bayesian Methods for Data Analysis third edition, Taylor & Francis Group 2009  

Three principal approaches to inference guide modern data analysis: frequentist, Bayesian, and likelihood.  


empirical Bayes (EB)  

In a nutshell, the Likelihood Principle states that once the data value x has been observed, the likelihood function L(θ|x) contains all relevant experimental information delivered by x about the unknown parameter θ.  

Many of these advantages are presented in detail in the popular textbook by Berger
* Bayesian methods provide the user with the ability to formally incorporate prior information.
* Inferences are conditional on the actual data.
* The reason for stopping the experimentation does not affect Bayesian inference.
* Bayesian answers are more easily interpretable by nonspecialists.
* All Bayesian analyses follow directly from the posterior; no separate theories of estimation, testing, multiple comparisons, etc. are needed.
* Any question can be directly answered through Bayesian analysis.
* Bayes and EB procedures possess numerous optimality properties.


The most basic Bayesian model has two stages, with a likelihood specification Y |θ ∼ f(y|θ) and a prior specification θ ∼ π(θ), where either Y or θ can be vectors.

K. Krishnamoorthy， Handbook of Statistical Distributions with Applications Second Edition，CRC Press， 2016  


Peter D. Hoff，A First Course in Bayesian Statistical Methods，Springer， 2009  


Bradley Efron and Trevor Hastie, Computer Age Statistical Inference: Algorithms, Evidence, and Data Science, Cambridge University Press, 2016


[Bayesian Inference](http://www.stat.cmu.edu/~larry/=sml/Bayes.pdf)


